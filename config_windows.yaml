data:
  dataset_root_windows: C:\Users\anaja\OneDrive\Documents\Ecole\TUHH\Semester 6\Masterarbeit\OCT_lab_data # D:\Masterarbeit\OCT_lab_data
  dataset_root_linux: /data/Boudreault/OCT_lab_data_raw
  ds_split: [0.6, 0.15, 0.25]
  labels:
    - chicken_heart
    - chicken_stomach
    - lamb_heart
    - lamb_testicle
    # - lamb_liver
  ascan_per_group: 5000
  use_mini_dataset: True  # Use only files with speed 8 to limit data storage size
training:
  random_seed: 2625233
  model: 'SPICE' # 'resnet18' 'efficientnet-b0'
SPICE:
  MoCo:
    dataset_name: oct # 'oct'  # [stl10, cifar10, cifar100]
    dataset_path_windows: C:\Users\anaja\OneDrive\Documents\Ecole\TUHH\Semester 6\Masterarbeit
    dataset_path_linux: C:\Users\anaja\OneDrive\Documents\Ecole\TUHH\Semester 6\Masterarbeit
    use_all: False   # True: Use train + test, False: Use only train
    base_model: 'resnet18' # 'clusterresnet'
    save_folder: ./results # Relative path from SPICE/tools or absolute path
    save_freq: 1 # How often the model will be saved
    num_workers: 4
    max_epochs: 1000
    start_epoch: 0  # Useful to restart training
    batch_size: 2 # 128
    lr: 0.015
    lr_schedule: [120, 160]  # when to drop lr by 10x
    momentum: 0.9
    weight_decay: 0.0001 # default: 1e-4
    print_freq: 10
    resume: False
    world_size: 1 # number of nodes for distributed training
    rank: 0 # node rank for distributed training
    dist_url: 'env://?use_libuv=False' # 'tcp://localhost:10001' # url used to set up distributed training
    dist_backend: 'gloo' # 'nccl'
    gpu_id: 0
    multiprocessing_distributed: True
    moco_queue_size: 1024 # 65536 # default: 65535
    moco_momentum: 0.999  # default: 0.999
    moco_softmax_temp: 0.07  # default: 0.07
    moco2_mlp: False
    moco2_aug_plus: False
    moco2_cos: False
  embedding:
    model_name: embedding
    weight: checkpoint_0016.pth.tar   # File path: [MoCo save_folder]/[MoCo dataset_name]/[embedding weight]
    batch_size: 1000
    data_test:
      shuffle: False
      imgs_per_batch: 50
      aspect_ratio_grouping: False
      train: False
      show: False
    model_sim:
      num_classes: 10 # 128
      in_channels: 3
      batchnorm_track: True
      test: False
      features_only: True
      model_type: "moco_embedding"
  SPICE_self:
    all: 0 # 1
    model_name: spice_self
    resume: False # Start again from ckp
    num_head: 10
    num_train: 5 # Not used??
    batch_size: 5000
    target_sub_batch_size: 100
    train_sub_batch_size: 128
    batch_size_test: 100
    num_trans_aug: 1 # Not used??
    num_repeat: 8
    fea_dim: 512
    att_size: 7
    center_ratio: 0.5
    sim_center_ratio: 0.9
    epochs: 100
    start_epoch: 0
    print_freq: 1
    test_freq: 1
    eval_ent: False
    eval_ent_weight: 0
  local_consistency:
    model_name: eval
    batch_size: 100
    batch_size_test: 1
  semi:
    model_name: 'spice_semi'
    resume: False
    overwrite: True
    epoch: 1
    num_train_iter: 2**20
    num_eval_iter: 1000
    num_labels: 6510
    batch_size: 32 # 64
    uratio: 7   # Ratio of unlabeled to labeled data in each mini-batch
    eval_batch_size: 1024
    hard_label: True
    T: 0.5l
    p_cutoff: 0.95
    ema_m: 0.999 # ema momentum for eval model
    ulb_loss_ratio: 1
    lr: 0.03
    momentum: 0.9
    weight_decay: 5e-4
    amp: False  # Use of mixed precision training or not
    net: 'WideResNet_stl10' # ['WideResNet', 'WideResNet_stl10', 'WideResNet_tiny', 'resnet18', 'resnet18_cifar', 'resnet34']
    net_from_name: False
    depth: 28
    widen_factor: 2
    leaky_slope: 0.1
    dropout: 0
    all: 0 # 1
    unlabeled: 0 # 1
    train_sampler: RandomSampler
SimCLR:
  dataset_name: stl10 # 'oct'  # [stl10, cifar10, cifar100]
  dataset_path_windows: C:\Users\anaja\OneDrive\Documents\Ecole\TUHH\Semester 6\Masterarbeit
  dataset_path_linux: C:\Users\anaja\OneDrive\Documents\Ecole\TUHH\Semester 6\Masterarbeit
  arch: resnet18 # --arch
  num_workers: 1
  max_epochs: 100
  batch_size: 128 # 256
  lr: 0.0003
  weight_decay: 0.0001
  disable_cuda: False
  fp16_precision: False
  log_every_n_steps: 100
  temperature: 0.07
  gpu_index: 0

wandb:
  wandb_log: False
  project_name: 'Test-project' # 'Test-project'  'Mandible-tracking'